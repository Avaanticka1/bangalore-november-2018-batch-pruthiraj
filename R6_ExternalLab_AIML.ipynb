{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YYk8NG3yOIT9"
   },
   "source": [
    "### A MNIST-like fashion product database\n",
    "\n",
    "In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFO6PuxzOIT_",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efNjNImfOIUC"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l9C4aAIGOIUH",
    "outputId": "5ef9aff6-a7bd-4b26-cba6-8750955f6ca3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcoZBStrOIUQ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XA1WsFSeOIUS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnbx7TyQOIUY"
   },
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbiHj5YPOIUc",
    "outputId": "87e1b9cd-07f0-45cb-e706-0d51ad742d72",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 1 6]\n"
     ]
    }
   ],
   "source": [
    "print(testY[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lDAYzkwyOIUj",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convert both training and testing labels into one-hot vectors.\n",
    "\n",
    "**Hint:** check **tf.keras.utils.to_categorical()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vBlfYlANOIUk"
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trn= to_categorical(trainY, num_classes=len(np.unique(trainY)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test= to_categorical(testY, num_classes=len(np.unique(testY)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RHV3b9mzOIUq",
    "outputId": "27bdfe58-91ee-4677-fe49-e742ad306c70",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "First 5 examples now are:  [9 0 0 3 0]\n"
     ]
    }
   ],
   "source": [
    "print(trainY.shape)\n",
    "print('First 5 examples now are: ', trainY[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwhQ8e7VOIUw"
   },
   "source": [
    "### Visualize the data\n",
    "\n",
    "Plot first 10 images in the triaining set and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvDML2OoOIUx",
    "outputId": "9dafc94e-61a8-4089-be03-d143163d68aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image:\n",
      "[9 0 0 3 0 2 7 2 5 5]\n"
     ]
    }
   ],
   "source": [
    "print (\"label for each of the above image:\")\n",
    "print (trainY[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(10):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(trainX[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(trainY[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4TbJGeSOIU4",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ac06XZZTOIU6"
   },
   "outputs": [],
   "source": [
    "#Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hQpLv3aOIU_",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Execute the model using model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O59C_-IgOIVB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 15.1256 - acc: 0.0538 - val_loss: 14.2723 - val_acc: 0.1125\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 14.2679 - acc: 0.1122 - val_loss: 13.8041 - val_acc: 0.1393\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 13.8326 - acc: 0.1369 - val_loss: 12.9302 - val_acc: 0.1923\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.9670 - acc: 0.1902 - val_loss: 12.8462 - val_acc: 0.1979\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.8806 - acc: 0.1954 - val_loss: 12.8615 - val_acc: 0.1971\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.8648 - acc: 0.1974 - val_loss: 13.1475 - val_acc: 0.1790\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 13.1705 - acc: 0.1770 - val_loss: 13.2339 - val_acc: 0.1773\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 13.2605 - acc: 0.1753 - val_loss: 13.1525 - val_acc: 0.1823\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 13.1288 - acc: 0.1832 - val_loss: 12.9663 - val_acc: 0.1927\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.9638 - acc: 0.1930 - val_loss: 12.7286 - val_acc: 0.2066\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.7303 - acc: 0.2067 - val_loss: 12.8013 - val_acc: 0.2017\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.8034 - acc: 0.2010 - val_loss: 12.8875 - val_acc: 0.1973\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.9026 - acc: 0.1968 - val_loss: 12.6713 - val_acc: 0.2111\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.6673 - acc: 0.2106 - val_loss: 12.6200 - val_acc: 0.2144\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.6204 - acc: 0.2132 - val_loss: 12.6071 - val_acc: 0.2149\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.5979 - acc: 0.2143 - val_loss: 12.5983 - val_acc: 0.2155\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.5856 - acc: 0.2155 - val_loss: 12.6018 - val_acc: 0.2151\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.5767 - acc: 0.2152 - val_loss: 12.7455 - val_acc: 0.2061\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.7523 - acc: 0.2055 - val_loss: 12.6909 - val_acc: 0.2088\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.6830 - acc: 0.2091 - val_loss: 12.9223 - val_acc: 0.1947\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.9373 - acc: 0.1943 - val_loss: 12.6244 - val_acc: 0.2134\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.5897 - acc: 0.2160 - val_loss: 12.5429 - val_acc: 0.2187\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.5025 - acc: 0.2205 - val_loss: 12.5716 - val_acc: 0.2170\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.5527 - acc: 0.2179 - val_loss: 12.6203 - val_acc: 0.2127\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 0s 4us/sample - loss: 12.5872 - acc: 0.2149 - val_loss: 12.7722 - val_acc: 0.2052\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.7803 - acc: 0.2041 - val_loss: 12.5113 - val_acc: 0.2209\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.4660 - acc: 0.2230 - val_loss: 12.4591 - val_acc: 0.2242\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.4082 - acc: 0.2266 - val_loss: 12.4308 - val_acc: 0.2250\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.4078 - acc: 0.2258 - val_loss: 12.5484 - val_acc: 0.2180\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.5532 - acc: 0.2175 - val_loss: 12.5010 - val_acc: 0.2204\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.4898 - acc: 0.2201 - val_loss: 12.7010 - val_acc: 0.2089\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.7085 - acc: 0.2084 - val_loss: 12.3527 - val_acc: 0.2301\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.3211 - acc: 0.2317 - val_loss: 12.3487 - val_acc: 0.2285\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.3091 - acc: 0.2310 - val_loss: 12.2630 - val_acc: 0.2335\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 0s 4us/sample - loss: 12.2574 - acc: 0.2339 - val_loss: 13.2986 - val_acc: 0.1717\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 13.2697 - acc: 0.1732 - val_loss: 12.4252 - val_acc: 0.2222\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.4241 - acc: 0.2235 - val_loss: 11.0165 - val_acc: 0.3135\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 10.9906 - acc: 0.3144 - val_loss: 11.0966 - val_acc: 0.3062\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 11.0971 - acc: 0.3060 - val_loss: 12.5079 - val_acc: 0.2190\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.4932 - acc: 0.2195 - val_loss: 12.7844 - val_acc: 0.2041\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 12.7690 - acc: 0.2050 - val_loss: 11.8686 - val_acc: 0.2603\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 0s 4us/sample - loss: 11.8917 - acc: 0.2580 - val_loss: 10.9795 - val_acc: 0.3152\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 10.9640 - acc: 0.3163 - val_loss: 10.8317 - val_acc: 0.3236\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 10.8181 - acc: 0.3252 - val_loss: 10.8137 - val_acc: 0.3261\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 10.7660 - acc: 0.3288 - val_loss: 10.7804 - val_acc: 0.3276\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 10.7511 - acc: 0.3288 - val_loss: 10.8613 - val_acc: 0.3226\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 10.8547 - acc: 0.3235 - val_loss: 10.7546 - val_acc: 0.3289\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 10.7171 - acc: 0.3311 - val_loss: 10.8487 - val_acc: 0.3242\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 10.8395 - acc: 0.3244 - val_loss: 10.7147 - val_acc: 0.3321\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 0s 5us/sample - loss: 10.6642 - acc: 0.3343 - val_loss: 10.7063 - val_acc: 0.3324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dc50e48>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, y_trn, \n",
    "          validation_data=(testX, y_test), \n",
    "          epochs=50,\n",
    "          batch_size=trainX.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JdzDtGwDOIVF",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kndfpdidOIVI"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "#Normalize the data\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mwk3T5LJOIVN",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JNLR8tcBOIVP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 3.2063 - acc: 0.0718 - val_loss: 13.6401 - val_acc: 0.0718\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 2.8699 - acc: 0.0948 - val_loss: 11.7935 - val_acc: 0.0741\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 2.5931 - acc: 0.1238 - val_loss: 9.4452 - val_acc: 0.0890\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3649 - acc: 0.1635 - val_loss: 7.2988 - val_acc: 0.1216\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 2.1761 - acc: 0.2094 - val_loss: 5.7400 - val_acc: 0.1694\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 2.0192 - acc: 0.2611 - val_loss: 4.7099 - val_acc: 0.2217\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 1.8883 - acc: 0.3122 - val_loss: 4.0294 - val_acc: 0.2717\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 1.7787 - acc: 0.3559 - val_loss: 3.5667 - val_acc: 0.3149\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 1.6862 - acc: 0.3927 - val_loss: 3.2365 - val_acc: 0.3522\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 1.6076 - acc: 0.4254 - val_loss: 2.9902 - val_acc: 0.3822\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 1.5402 - acc: 0.4534 - val_loss: 2.7980 - val_acc: 0.4100\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 1.4819 - acc: 0.4764 - val_loss: 2.6426 - val_acc: 0.4357\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 1.4310 - acc: 0.4964 - val_loss: 2.5129 - val_acc: 0.4562\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 1.3863 - acc: 0.5139 - val_loss: 2.4017 - val_acc: 0.4725\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 1.3467 - acc: 0.5302 - val_loss: 2.3044 - val_acc: 0.4874\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 1.3114 - acc: 0.5445 - val_loss: 2.2181 - val_acc: 0.5021\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 1.2797 - acc: 0.5575 - val_loss: 2.1407 - val_acc: 0.5145\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 1.2511 - acc: 0.5694 - val_loss: 2.0706 - val_acc: 0.5266\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 1.2252 - acc: 0.5793 - val_loss: 2.0065 - val_acc: 0.5363\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 1.2016 - acc: 0.5882 - val_loss: 1.9476 - val_acc: 0.5457\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 1.1800 - acc: 0.5966 - val_loss: 1.8934 - val_acc: 0.5544\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 1.1602 - acc: 0.6040 - val_loss: 1.8430 - val_acc: 0.5613\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 1.1418 - acc: 0.6104 - val_loss: 1.7962 - val_acc: 0.5686\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 1.1248 - acc: 0.6162 - val_loss: 1.7525 - val_acc: 0.5749\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 1.1090 - acc: 0.6218 - val_loss: 1.7116 - val_acc: 0.5803\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 1.0943 - acc: 0.6267 - val_loss: 1.6732 - val_acc: 0.5857\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 1.0804 - acc: 0.6316 - val_loss: 1.6370 - val_acc: 0.5895\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 1.0674 - acc: 0.6361 - val_loss: 1.6029 - val_acc: 0.5940\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 1.0552 - acc: 0.6400 - val_loss: 1.5707 - val_acc: 0.5981\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 1.0437 - acc: 0.6440 - val_loss: 1.5402 - val_acc: 0.6032\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 1.0327 - acc: 0.6474 - val_loss: 1.5114 - val_acc: 0.6072\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 1.0223 - acc: 0.6511 - val_loss: 1.4840 - val_acc: 0.6093\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 1.0125 - acc: 0.6546 - val_loss: 1.4579 - val_acc: 0.6128\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 1.0031 - acc: 0.6575 - val_loss: 1.4331 - val_acc: 0.6158\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.9941 - acc: 0.6606 - val_loss: 1.4095 - val_acc: 0.6191\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.9855 - acc: 0.6633 - val_loss: 1.3870 - val_acc: 0.6217\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.9773 - acc: 0.6661 - val_loss: 1.3655 - val_acc: 0.6249\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.9695 - acc: 0.6687 - val_loss: 1.3449 - val_acc: 0.6277\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.9619 - acc: 0.6711 - val_loss: 1.3252 - val_acc: 0.6304\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.9547 - acc: 0.6735 - val_loss: 1.3062 - val_acc: 0.6337\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.9477 - acc: 0.6761 - val_loss: 1.2881 - val_acc: 0.6351\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.9410 - acc: 0.6780 - val_loss: 1.2707 - val_acc: 0.6385\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.9345 - acc: 0.6800 - val_loss: 1.2539 - val_acc: 0.6409\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.9283 - acc: 0.6820 - val_loss: 1.2378 - val_acc: 0.6429\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.9222 - acc: 0.6840 - val_loss: 1.2224 - val_acc: 0.6452\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.9164 - acc: 0.6854 - val_loss: 1.2075 - val_acc: 0.6470\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.9107 - acc: 0.6872 - val_loss: 1.1932 - val_acc: 0.6493\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.9053 - acc: 0.6893 - val_loss: 1.1793 - val_acc: 0.6510\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.9000 - acc: 0.6911 - val_loss: 1.1660 - val_acc: 0.6526\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.8948 - acc: 0.6925 - val_loss: 1.1532 - val_acc: 0.6549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1de5f358>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, y_trn, \n",
    "          validation_data=(testX, y_test), \n",
    "          epochs=50,\n",
    "          batch_size=trainX.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Py-KwkmjOIVU"
   },
   "source": [
    "### Customize the learning rate to 0.001 in sgd optimizer and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLXUE9jWOIVV"
   },
   "outputs": [],
   "source": [
    "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJUqA5T4OIVc"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.8898 - acc: 0.6941 - val_loss: 1.1439 - val_acc: 0.6552\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8894 - acc: 0.6944 - val_loss: 1.1350 - val_acc: 0.6565\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.8889 - acc: 0.6946 - val_loss: 1.1265 - val_acc: 0.6577\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.8884 - acc: 0.6948 - val_loss: 1.1182 - val_acc: 0.6595\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8879 - acc: 0.6949 - val_loss: 1.1102 - val_acc: 0.6603\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8874 - acc: 0.6951 - val_loss: 1.1026 - val_acc: 0.6609\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8869 - acc: 0.6951 - val_loss: 1.0951 - val_acc: 0.6619\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8865 - acc: 0.6952 - val_loss: 1.0880 - val_acc: 0.6627\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.8860 - acc: 0.6954 - val_loss: 1.0811 - val_acc: 0.6634\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.8855 - acc: 0.6956 - val_loss: 1.0744 - val_acc: 0.6645\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.8850 - acc: 0.6957 - val_loss: 1.0679 - val_acc: 0.6654\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.8846 - acc: 0.6960 - val_loss: 1.0617 - val_acc: 0.6664\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8841 - acc: 0.6962 - val_loss: 1.0557 - val_acc: 0.6673\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.8836 - acc: 0.6963 - val_loss: 1.0498 - val_acc: 0.6678\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.8831 - acc: 0.6963 - val_loss: 1.0442 - val_acc: 0.6690\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8827 - acc: 0.6965 - val_loss: 1.0387 - val_acc: 0.6689\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8822 - acc: 0.6967 - val_loss: 1.0334 - val_acc: 0.6699\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.8817 - acc: 0.6968 - val_loss: 1.0282 - val_acc: 0.6704\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8813 - acc: 0.6969 - val_loss: 1.0233 - val_acc: 0.6715\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.8808 - acc: 0.6970 - val_loss: 1.0184 - val_acc: 0.6726\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.8804 - acc: 0.6971 - val_loss: 1.0138 - val_acc: 0.6731\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8799 - acc: 0.6972 - val_loss: 1.0092 - val_acc: 0.6744\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.8794 - acc: 0.6973 - val_loss: 1.0048 - val_acc: 0.6740\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.8790 - acc: 0.6974 - val_loss: 1.0006 - val_acc: 0.6752\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8785 - acc: 0.6976 - val_loss: 0.9964 - val_acc: 0.6756\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.8781 - acc: 0.6977 - val_loss: 0.9924 - val_acc: 0.6764\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8776 - acc: 0.6978 - val_loss: 0.9885 - val_acc: 0.6769\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8772 - acc: 0.6981 - val_loss: 0.9847 - val_acc: 0.6774\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8767 - acc: 0.6984 - val_loss: 0.9810 - val_acc: 0.6781\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8763 - acc: 0.6984 - val_loss: 0.9774 - val_acc: 0.6789\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8758 - acc: 0.6986 - val_loss: 0.9740 - val_acc: 0.6794\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.8754 - acc: 0.6988 - val_loss: 0.9706 - val_acc: 0.6808\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.8749 - acc: 0.6989 - val_loss: 0.9673 - val_acc: 0.6813\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8745 - acc: 0.6991 - val_loss: 0.9641 - val_acc: 0.6817\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.8740 - acc: 0.6992 - val_loss: 0.9610 - val_acc: 0.6822\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8736 - acc: 0.6993 - val_loss: 0.9580 - val_acc: 0.6833\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8731 - acc: 0.6995 - val_loss: 0.9551 - val_acc: 0.6843\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8727 - acc: 0.6996 - val_loss: 0.9522 - val_acc: 0.6849\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8723 - acc: 0.6997 - val_loss: 0.9494 - val_acc: 0.6856\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8718 - acc: 0.6999 - val_loss: 0.9467 - val_acc: 0.6863\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8714 - acc: 0.7001 - val_loss: 0.9441 - val_acc: 0.6865\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8709 - acc: 0.7004 - val_loss: 0.9415 - val_acc: 0.6866\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.8705 - acc: 0.7005 - val_loss: 0.9390 - val_acc: 0.6870\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.8701 - acc: 0.7007 - val_loss: 0.9366 - val_acc: 0.6872\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8696 - acc: 0.7009 - val_loss: 0.9342 - val_acc: 0.6879\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8692 - acc: 0.7010 - val_loss: 0.9319 - val_acc: 0.6888\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8688 - acc: 0.7011 - val_loss: 0.9297 - val_acc: 0.6892\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8683 - acc: 0.7013 - val_loss: 0.9275 - val_acc: 0.6896\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8679 - acc: 0.7015 - val_loss: 0.9253 - val_acc: 0.6898\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.8675 - acc: 0.7017 - val_loss: 0.9233 - val_acc: 0.6903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26a5fe10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, y_trn, \n",
    "          validation_data=(testX, y_test), \n",
    "          epochs=50,\n",
    "          batch_size=trainX.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9CSqKvpOIVk",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGAad54JOIVm"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQ7oIymROIVp"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=sgd_optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nr2YsZV0OIV0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4ojW6-oOIV2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.9678 - acc: 0.5699 - val_loss: 1.9651 - val_acc: 0.5691\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.9629 - acc: 0.5717 - val_loss: 1.9603 - val_acc: 0.5696\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.9580 - acc: 0.5727 - val_loss: 1.9554 - val_acc: 0.5719\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.9530 - acc: 0.5747 - val_loss: 1.9505 - val_acc: 0.5733\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.9482 - acc: 0.5767 - val_loss: 1.9456 - val_acc: 0.5747\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.9435 - acc: 0.5784 - val_loss: 1.9410 - val_acc: 0.5759\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.9389 - acc: 0.5802 - val_loss: 1.9367 - val_acc: 0.5763\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.9344 - acc: 0.5816 - val_loss: 1.9322 - val_acc: 0.5775\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.9300 - acc: 0.5831 - val_loss: 1.9278 - val_acc: 0.5810\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.9256 - acc: 0.5854 - val_loss: 1.9234 - val_acc: 0.5828\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.9212 - acc: 0.5871 - val_loss: 1.9190 - val_acc: 0.5849\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.9169 - acc: 0.5882 - val_loss: 1.9149 - val_acc: 0.5873\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.9126 - acc: 0.5890 - val_loss: 1.9108 - val_acc: 0.5873\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.9084 - acc: 0.5904 - val_loss: 1.9066 - val_acc: 0.5882\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.9041 - acc: 0.5924 - val_loss: 1.9025 - val_acc: 0.5898\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.9000 - acc: 0.5943 - val_loss: 1.8985 - val_acc: 0.5920\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8959 - acc: 0.5965 - val_loss: 1.8945 - val_acc: 0.5942\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8918 - acc: 0.5983 - val_loss: 1.8904 - val_acc: 0.5951\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.8877 - acc: 0.6003 - val_loss: 1.8864 - val_acc: 0.5964\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8836 - acc: 0.6025 - val_loss: 1.8823 - val_acc: 0.5988\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8796 - acc: 0.6043 - val_loss: 1.8783 - val_acc: 0.5997\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.8755 - acc: 0.6055 - val_loss: 1.8742 - val_acc: 0.6017\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8715 - acc: 0.6065 - val_loss: 1.8702 - val_acc: 0.6035\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8674 - acc: 0.6080 - val_loss: 1.8661 - val_acc: 0.6050\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8633 - acc: 0.6097 - val_loss: 1.8621 - val_acc: 0.6065\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.8593 - acc: 0.6108 - val_loss: 1.8581 - val_acc: 0.6083\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.8553 - acc: 0.6129 - val_loss: 1.8541 - val_acc: 0.6110\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.8512 - acc: 0.6144 - val_loss: 1.8500 - val_acc: 0.6129\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.8471 - acc: 0.6160 - val_loss: 1.8460 - val_acc: 0.6141\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.8431 - acc: 0.6174 - val_loss: 1.8420 - val_acc: 0.6154\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8391 - acc: 0.6185 - val_loss: 1.8381 - val_acc: 0.6166\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8351 - acc: 0.6194 - val_loss: 1.8341 - val_acc: 0.6183\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8311 - acc: 0.6202 - val_loss: 1.8302 - val_acc: 0.6184\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.8271 - acc: 0.6213 - val_loss: 1.8263 - val_acc: 0.6190\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.8232 - acc: 0.6223 - val_loss: 1.8224 - val_acc: 0.6203\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8192 - acc: 0.6230 - val_loss: 1.8184 - val_acc: 0.6209\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8152 - acc: 0.6241 - val_loss: 1.8145 - val_acc: 0.6210\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.8113 - acc: 0.6251 - val_loss: 1.8106 - val_acc: 0.6226\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 1.8073 - acc: 0.6261 - val_loss: 1.8068 - val_acc: 0.6237\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8034 - acc: 0.6278 - val_loss: 1.8029 - val_acc: 0.6247\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.7995 - acc: 0.6288 - val_loss: 1.7991 - val_acc: 0.6247\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.7956 - acc: 0.6297 - val_loss: 1.7952 - val_acc: 0.6262\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.7917 - acc: 0.6302 - val_loss: 1.7914 - val_acc: 0.6265\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.7879 - acc: 0.6305 - val_loss: 1.7876 - val_acc: 0.6268\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.7841 - acc: 0.6315 - val_loss: 1.7838 - val_acc: 0.6282\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.7803 - acc: 0.6324 - val_loss: 1.7801 - val_acc: 0.6288\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.7765 - acc: 0.6330 - val_loss: 1.7763 - val_acc: 0.6294\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.7727 - acc: 0.6338 - val_loss: 1.7725 - val_acc: 0.6300\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.7688 - acc: 0.6347 - val_loss: 1.7688 - val_acc: 0.6303\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.7650 - acc: 0.6356 - val_loss: 1.7650 - val_acc: 0.6314\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.7612 - acc: 0.6363 - val_loss: 1.7612 - val_acc: 0.6323\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.7574 - acc: 0.6370 - val_loss: 1.7574 - val_acc: 0.6336\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.7536 - acc: 0.6377 - val_loss: 1.7537 - val_acc: 0.6335\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.7498 - acc: 0.6386 - val_loss: 1.7499 - val_acc: 0.6347\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.7461 - acc: 0.6390 - val_loss: 1.7462 - val_acc: 0.6346\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.7423 - acc: 0.6397 - val_loss: 1.7425 - val_acc: 0.6354\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.7386 - acc: 0.6403 - val_loss: 1.7388 - val_acc: 0.6365\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.7348 - acc: 0.6409 - val_loss: 1.7351 - val_acc: 0.6368\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.7310 - acc: 0.6415 - val_loss: 1.7314 - val_acc: 0.6374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.7272 - acc: 0.6419 - val_loss: 1.7277 - val_acc: 0.6382\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.7234 - acc: 0.6426 - val_loss: 1.7240 - val_acc: 0.6397\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.7197 - acc: 0.6434 - val_loss: 1.7203 - val_acc: 0.6405\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.7160 - acc: 0.6437 - val_loss: 1.7167 - val_acc: 0.6412\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.7123 - acc: 0.6445 - val_loss: 1.7130 - val_acc: 0.6412\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.7086 - acc: 0.6456 - val_loss: 1.7094 - val_acc: 0.6420\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.7050 - acc: 0.6463 - val_loss: 1.7057 - val_acc: 0.6426\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.7013 - acc: 0.6472 - val_loss: 1.7021 - val_acc: 0.6431\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6977 - acc: 0.6478 - val_loss: 1.6985 - val_acc: 0.6432\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6940 - acc: 0.6485 - val_loss: 1.6949 - val_acc: 0.6433\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6904 - acc: 0.6494 - val_loss: 1.6913 - val_acc: 0.6427\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6867 - acc: 0.6501 - val_loss: 1.6877 - val_acc: 0.6432\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6831 - acc: 0.6509 - val_loss: 1.6841 - val_acc: 0.6437\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6794 - acc: 0.6512 - val_loss: 1.6805 - val_acc: 0.6442\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6758 - acc: 0.6515 - val_loss: 1.6769 - val_acc: 0.6449\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6721 - acc: 0.6518 - val_loss: 1.6734 - val_acc: 0.6459\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6685 - acc: 0.6525 - val_loss: 1.6698 - val_acc: 0.6468\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6649 - acc: 0.6530 - val_loss: 1.6662 - val_acc: 0.6475\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6614 - acc: 0.6538 - val_loss: 1.6626 - val_acc: 0.6475\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6578 - acc: 0.6546 - val_loss: 1.6591 - val_acc: 0.6473\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6543 - acc: 0.6551 - val_loss: 1.6557 - val_acc: 0.6485\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6508 - acc: 0.6555 - val_loss: 1.6522 - val_acc: 0.6500\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6473 - acc: 0.6558 - val_loss: 1.6488 - val_acc: 0.6501\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6438 - acc: 0.6565 - val_loss: 1.6454 - val_acc: 0.6505\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6404 - acc: 0.6572 - val_loss: 1.6420 - val_acc: 0.6515\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6369 - acc: 0.6577 - val_loss: 1.6386 - val_acc: 0.6519\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.6335 - acc: 0.6580 - val_loss: 1.6352 - val_acc: 0.6524\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6300 - acc: 0.6583 - val_loss: 1.6318 - val_acc: 0.6531\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6266 - acc: 0.6587 - val_loss: 1.6284 - val_acc: 0.6530\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6232 - acc: 0.6592 - val_loss: 1.6250 - val_acc: 0.6533\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.6198 - acc: 0.6598 - val_loss: 1.6216 - val_acc: 0.6533\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.6165 - acc: 0.6603 - val_loss: 1.6182 - val_acc: 0.6538\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6131 - acc: 0.6610 - val_loss: 1.6149 - val_acc: 0.6540\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6098 - acc: 0.6613 - val_loss: 1.6116 - val_acc: 0.6545\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6064 - acc: 0.6618 - val_loss: 1.6083 - val_acc: 0.6553\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.6031 - acc: 0.6625 - val_loss: 1.6050 - val_acc: 0.6559\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.5998 - acc: 0.6628 - val_loss: 1.6017 - val_acc: 0.6569\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.5965 - acc: 0.6632 - val_loss: 1.5985 - val_acc: 0.6570\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.5932 - acc: 0.6635 - val_loss: 1.5952 - val_acc: 0.6568\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.5899 - acc: 0.6634 - val_loss: 1.5920 - val_acc: 0.6580\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.5867 - acc: 0.6636 - val_loss: 1.5888 - val_acc: 0.6577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2797e6a0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, y_trn, \n",
    "          validation_data=(testX, y_test), \n",
    "          epochs=100,\n",
    "          batch_size=trainX.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gfFGmbZLOIV5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bIkbMEN5OIV7"
   },
   "outputs": [],
   "source": [
    "y_predict=model.predict_classes(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6577"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(testY,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.79      0.71      1000\n",
      "          1       0.88      0.93      0.90      1000\n",
      "          2       0.47      0.66      0.55      1000\n",
      "          3       0.73      0.78      0.75      1000\n",
      "          4       0.50      0.56      0.53      1000\n",
      "          5       0.95      0.19      0.32      1000\n",
      "          6       0.42      0.08      0.14      1000\n",
      "          7       0.59      0.91      0.72      1000\n",
      "          8       0.91      0.77      0.83      1000\n",
      "          9       0.68      0.91      0.78      1000\n",
      "\n",
      "avg / total       0.68      0.66      0.62     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr=metrics.classification_report(testY,y_predict)\n",
    "print(cr)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "R6_ExternalLab_AIML.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
