{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the basic Image Classification pipeline and the data-driven approach (train/predict stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = h5py.File(\"SVHN_single_grey1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data fetching and understand the train/val/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = data['X_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data['X_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data['y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = data['X_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = data['y_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 32, 32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 32, 32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 32, 32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement and apply an optimal k-Nearest Neighbor (kNN) classifier (7.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.reshape(x_train,(42000,32*32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.reshape(x_test,(18000,32*32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 1024)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 1024)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=15, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the classification metric report (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5235555555555556\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Metrix:   \n",
      " [[1233   95  100  136  117  163  318   98  249  335]\n",
      " [  68 1335  215  251  247  164  122  227  115  137]\n",
      " [  39   70  992  136   41   62   38  116   62   70]\n",
      " [  39   83  107  734   60  268   72   84  119   92]\n",
      " [  51   75   55   50 1182   63  129   26  100   65]\n",
      " [  46   34   30  160   14  683  128   35  120  108]\n",
      " [ 113   32   37   42   54  156  741   35  253   56]\n",
      " [  37   51  138   54   17   31   23 1116   28   69]\n",
      " [  86   21   54   98   34  114  210   30  655  119]\n",
      " [ 102   32   75   58   46   64   51   41  111  753]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Metrix:   \\n\", metrics.confusion_matrix(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.68      0.53      1814\n",
      "           1       0.46      0.73      0.57      1828\n",
      "           2       0.61      0.55      0.58      1803\n",
      "           3       0.44      0.43      0.43      1719\n",
      "           4       0.66      0.65      0.66      1812\n",
      "           5       0.50      0.39      0.44      1768\n",
      "           6       0.49      0.40      0.44      1832\n",
      "           7       0.71      0.62      0.66      1808\n",
      "           8       0.46      0.36      0.41      1812\n",
      "           9       0.56      0.42      0.48      1804\n",
      "\n",
      "   micro avg       0.52      0.52      0.52     18000\n",
      "   macro avg       0.53      0.52      0.52     18000\n",
      "weighted avg       0.53      0.52      0.52     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr=metrics.classification_report(y_test,prediction)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement and apply a deep neural network classifier including (feedforward neural network, RELU activations) (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape data from 2D to 1D -> 32X32 to 1024\n",
    "model.add(tf.keras.layers.Reshape((1024,),input_shape=(32,32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement batch normalization for training the neural network (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Normalize the data\n",
    "model.add(tf.keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(200, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax', name='Output'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand and be able to implement (vectorized) backpropagation (cost stochastic gradient descent, cross entropy loss, cost functions) (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the differences and trade-offs between traditional and NN classifiers with the help of classification metrics (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change train and test labels into one-hot vectors¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "testY = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 32, 32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 32, 32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 32, 32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "42000/42000 [==============================] - 16s 391us/sample - loss: 2.0406 - acc: 0.3003 - val_loss: 1.6598 - val_acc: 0.4977\n",
      "Epoch 2/30\n",
      "42000/42000 [==============================] - 5s 118us/sample - loss: 1.4433 - acc: 0.5698 - val_loss: 1.2353 - val_acc: 0.6418\n",
      "Epoch 3/30\n",
      "42000/42000 [==============================] - 4s 106us/sample - loss: 1.1613 - acc: 0.6587 - val_loss: 1.0577 - val_acc: 0.6944\n",
      "Epoch 4/30\n",
      "42000/42000 [==============================] - 5s 110us/sample - loss: 1.0247 - acc: 0.6976 - val_loss: 0.9621 - val_acc: 0.7221\n",
      "Epoch 5/30\n",
      "42000/42000 [==============================] - 6s 132us/sample - loss: 0.9372 - acc: 0.7235 - val_loss: 0.8964 - val_acc: 0.7384\n",
      "Epoch 6/30\n",
      "42000/42000 [==============================] - 4s 107us/sample - loss: 0.8712 - acc: 0.7417 - val_loss: 0.8556 - val_acc: 0.7523\n",
      "Epoch 7/30\n",
      "42000/42000 [==============================] - 5s 109us/sample - loss: 0.8175 - acc: 0.7569 - val_loss: 0.8181 - val_acc: 0.7636\n",
      "Epoch 8/30\n",
      "42000/42000 [==============================] - 5s 128us/sample - loss: 0.7734 - acc: 0.7698 - val_loss: 0.7810 - val_acc: 0.7727\n",
      "Epoch 9/30\n",
      "42000/42000 [==============================] - 4s 102us/sample - loss: 0.7352 - acc: 0.7800 - val_loss: 0.7666 - val_acc: 0.7779\n",
      "Epoch 10/30\n",
      "42000/42000 [==============================] - 5s 108us/sample - loss: 0.7007 - acc: 0.7900 - val_loss: 0.7457 - val_acc: 0.7815\n",
      "Epoch 11/30\n",
      "42000/42000 [==============================] - 4s 106us/sample - loss: 0.6734 - acc: 0.7985 - val_loss: 0.7126 - val_acc: 0.7971\n",
      "Epoch 12/30\n",
      "42000/42000 [==============================] - 6s 139us/sample - loss: 0.6471 - acc: 0.8061 - val_loss: 0.6936 - val_acc: 0.8020\n",
      "Epoch 13/30\n",
      "42000/42000 [==============================] - 5s 109us/sample - loss: 0.6228 - acc: 0.8132 - val_loss: 0.6862 - val_acc: 0.8051\n",
      "Epoch 14/30\n",
      "42000/42000 [==============================] - 5s 115us/sample - loss: 0.6030 - acc: 0.8206 - val_loss: 0.6794 - val_acc: 0.8073\n",
      "Epoch 15/30\n",
      "42000/42000 [==============================] - 7s 161us/sample - loss: 0.5824 - acc: 0.8256 - val_loss: 0.6568 - val_acc: 0.8152\n",
      "Epoch 16/30\n",
      "42000/42000 [==============================] - 4s 107us/sample - loss: 0.5655 - acc: 0.8307 - val_loss: 0.6534 - val_acc: 0.8162\n",
      "Epoch 17/30\n",
      "42000/42000 [==============================] - 4s 103us/sample - loss: 0.5493 - acc: 0.8347 - val_loss: 0.6407 - val_acc: 0.8221\n",
      "Epoch 18/30\n",
      "42000/42000 [==============================] - 5s 130us/sample - loss: 0.5328 - acc: 0.8413 - val_loss: 0.6334 - val_acc: 0.8234\n",
      "Epoch 19/30\n",
      "42000/42000 [==============================] - 4s 106us/sample - loss: 0.5217 - acc: 0.8455 - val_loss: 0.6234 - val_acc: 0.8274\n",
      "Epoch 20/30\n",
      "42000/42000 [==============================] - 5s 113us/sample - loss: 0.5061 - acc: 0.8496 - val_loss: 0.6177 - val_acc: 0.8282\n",
      "Epoch 21/30\n",
      "42000/42000 [==============================] - 6s 138us/sample - loss: 0.4960 - acc: 0.8530 - val_loss: 0.6322 - val_acc: 0.8244\n",
      "Epoch 22/30\n",
      "42000/42000 [==============================] - 5s 108us/sample - loss: 0.4833 - acc: 0.8553 - val_loss: 0.6167 - val_acc: 0.8287\n",
      "Epoch 23/30\n",
      "42000/42000 [==============================] - 5s 108us/sample - loss: 0.4712 - acc: 0.8604 - val_loss: 0.6101 - val_acc: 0.8300\n",
      "Epoch 24/30\n",
      "42000/42000 [==============================] - 5s 122us/sample - loss: 0.4608 - acc: 0.8638 - val_loss: 0.6203 - val_acc: 0.8262\n",
      "Epoch 25/30\n",
      "42000/42000 [==============================] - 5s 119us/sample - loss: 0.4525 - acc: 0.8640 - val_loss: 0.5983 - val_acc: 0.8343\n",
      "Epoch 26/30\n",
      "42000/42000 [==============================] - 5s 110us/sample - loss: 0.4440 - acc: 0.8672 - val_loss: 0.6010 - val_acc: 0.8328\n",
      "Epoch 27/30\n",
      "42000/42000 [==============================] - 5s 110us/sample - loss: 0.4363 - acc: 0.8705 - val_loss: 0.6070 - val_acc: 0.8324\n",
      "Epoch 28/30\n",
      "42000/42000 [==============================] - 5s 128us/sample - loss: 0.4266 - acc: 0.8721 - val_loss: 0.6136 - val_acc: 0.8302\n",
      "Epoch 29/30\n",
      "42000/42000 [==============================] - 5s 107us/sample - loss: 0.4175 - acc: 0.8759 - val_loss: 0.5939 - val_acc: 0.8363\n",
      "Epoch 30/30\n",
      "42000/42000 [==============================] - 5s 113us/sample - loss: 0.4097 - acc: 0.8771 - val_loss: 0.5889 - val_acc: 0.8392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x4276db38>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "features_val_arr = np.array(x_test)\n",
    "model.fit(x_train,trainY,          \n",
    "          validation_data=(features_val_arr, testY),\n",
    "          epochs=30,\n",
    "          batch_size=100,validation_split = 0.01,\n",
    "         shuffle='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 2s 96us/sample - loss: 0.5889 - acc: 0.83920s - loss: 0.5828 - acc: 0.8\n",
      "[0.5889296860694885, 0.8392222]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(x_test, testY)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86      1814\n",
      "           1       0.84      0.86      0.85      1828\n",
      "           2       0.88      0.83      0.86      1803\n",
      "           3       0.80      0.78      0.79      1719\n",
      "           4       0.86      0.87      0.87      1812\n",
      "           5       0.81      0.85      0.83      1768\n",
      "           6       0.87      0.81      0.84      1832\n",
      "           7       0.87      0.88      0.88      1808\n",
      "           8       0.82      0.80      0.81      1812\n",
      "           9       0.80      0.83      0.82      1804\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     18000\n",
      "   macro avg       0.84      0.84      0.84     18000\n",
      "weighted avg       0.84      0.84      0.84     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr=metrics.classification_report(y_test,y_predict)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the classification report for convectional KNN and Neural Network we can see that KNN has very low accuracy score and very low F1 score for each category. The reason is KNN does not learn from the provided feature and tries to classify with the help of distance formulas. In Neural networks, the hidden layers learn the image features by adjusting the weights and is able to classify better than convectional models. This is evident from F1 score for each labels for Neural networks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
